{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommendation System\n",
        "\n",
        "This project implements a Hybrid Movie Recommendation System that combines both content-based and collaborative filtering techniques to generate personalized movie recommendations. The content-based filtering component leverages the TF-IDF vectorization of movie genres and titles to compute similarity between movies, while the collaborative filtering component uses a neural network model with user and movie embeddings to predict ratings. The system integrates both methods by combining their respective similarity scores, providing more accurate and diverse recommendations. The model is trained on the MovieLens dataset, and the hybrid approach aims to enhance recommendation quality by considering both user preferences and movie characteristics. Additionally, the system includes evaluation metrics such as genre match rate to assess the relevance of the recommendations.\n",
        "\n",
        "The MovieLens dataset provides rich data, including:\n",
        "- **User Ratings**: The ratings users have given to movies on a scale of 1 to 5.\n",
        "- **Movie Metadata**: Details about the movies such as titles, genres, and release years.\n",
        "\n",
        "### Hybrid Approach Overview\n",
        "\n",
        "- **Collaborative Filtering**: This technique identifies patterns by analyzing user-item interactions. We use **user-based** or **item-based** collaborative filtering to recommend movies based on the preferences of similar users or similar movies.\n",
        "- **Content-Based Filtering**: This method focuses on the characteristics of the movies themselves. It recommends movies based on features like genre, description, and keywords that match the user's past preferences.\n",
        "\n",
        "By combining these two techniques, the hybrid approach aims to improve the accuracy of predictions, especially when one method has limitations. For example, collaborative filtering might struggle with new or unpopular movies, while content-based filtering may have difficulty recommending diverse options.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "- Preprocess and analyze the data.\n",
        "- Implement both collaborative filtering and content-based filtering methods.\n",
        "- Build and evaluate the hybrid model to generate movie recommendations.\n",
        "- Fine-tune the system to enhance recommendation quality.\n"
      ],
      "metadata": {
        "id": "-RgIo6zqMJQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data"
      ],
      "metadata": {
        "id": "Y60jvVFBPhRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af9h0p-JL_nY",
        "outputId": "fe51fc75-8adc-4e5d-ac0d-c3f7540d6be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-02 18:06:49--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K   773KB/s    in 1.2s    \n",
            "\n",
            "2025-01-02 18:06:52 (773 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ],
      "source": [
        "# Download MovieLens dataset\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "dhlMsnuNNWRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
      ],
      "metadata": {
        "id": "Rxqbe9EPNfJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying the structure of the dataset"
      ],
      "metadata": {
        "id": "qs_qiQ6jNJhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
        "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "links_df = pd.read_csv('ml-latest-small/links.csv')\n",
        "\n",
        "# Display the first few rows of each dataframe\n",
        "print(\"Movies Dataset:\")\n",
        "print(movies_df.head())\n",
        "\n",
        "print(\"\\nRatings Dataset:\")\n",
        "print(ratings_df.head())\n",
        "\n",
        "print(\"\\nLinks Dataset:\")\n",
        "print(links_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_wuyoCUNJQD",
        "outputId": "81eaae08-c451-4ff8-ee08-f263037d981c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies Dataset:\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n",
            "\n",
            "Ratings Dataset:\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "\n",
            "Links Dataset:\n",
            "   movieId  imdbId   tmdbId\n",
            "0        1  114709    862.0\n",
            "1        2  113497   8844.0\n",
            "2        3  113228  15602.0\n",
            "3        4  114885  31357.0\n",
            "4        5  113041  11862.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess movie data"
      ],
      "metadata": {
        "id": "AA-wFt87NpeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a combined text feature for content-based filtering\n",
        "movies_df['content_features'] = movies_df['genres'] + ' ' + movies_df['title']\n"
      ],
      "metadata": {
        "id": "ps93b0j9NurH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content-Based Filtering Component\n",
        "\n",
        "### 1. TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "mvjw3ZUbNzoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies_df['content_features'])\n",
        "\n",
        "# Compute content-based similarity matrix\n",
        "content_sim_matrix = cosine_similarity(tfidf_matrix)"
      ],
      "metadata": {
        "id": "70btA24ZN3G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collaborative Filtering Preprocessing"
      ],
      "metadata": {
        "id": "hYlajaJnN_xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode users and movies\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "\n",
        "ratings_df['user_id_encoded'] = user_encoder.fit_transform(ratings_df['userId'])\n",
        "ratings_df['movie_id_encoded'] = movie_encoder.fit_transform(ratings_df['movieId'])\n"
      ],
      "metadata": {
        "id": "jWthW4tyOJQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "user-movie rating matrix"
      ],
      "metadata": {
        "id": "gAPEwvhkOMMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_movie_matrix = ratings_df.pivot(\n",
        "    index='user_id_encoded',\n",
        "    columns='movie_id_encoded',\n",
        "    values='rating'\n",
        ").fillna(0)"
      ],
      "metadata": {
        "id": "YV9l84KrOOtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative Filtering Neural Network Model"
      ],
      "metadata": {
        "id": "rAsixd5KOTn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_hybrid_model(num_users, num_movies, embedding_size=50):\n",
        "    # User input\n",
        "    user_input = tf.keras.layers.Input(shape=(1,), name='user_input')\n",
        "\n",
        "    # Movie input\n",
        "    movie_input = tf.keras.layers.Input(shape=(1,), name='movie_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    user_embedding = tf.keras.layers.Embedding(\n",
        "        num_users, embedding_size,\n",
        "        embeddings_initializer='he_normal',\n",
        "        input_length=1,\n",
        "        name='user_embedding'\n",
        "    )(user_input)\n",
        "    movie_embedding = tf.keras.layers.Embedding(\n",
        "        num_movies, embedding_size,\n",
        "        embeddings_initializer='he_normal',\n",
        "        input_length=1,\n",
        "        name='movie_embedding'\n",
        "    )(movie_input)\n",
        "\n",
        "    # Flatten embeddings\n",
        "    user_vector = tf.keras.layers.Flatten()(user_embedding)\n",
        "    movie_vector = tf.keras.layers.Flatten()(movie_embedding)\n",
        "\n",
        "    # Concatenate user and movie embeddings\n",
        "    concatenated = tf.keras.layers.Concatenate()([user_vector, movie_vector])\n",
        "\n",
        "    # Deep layers\n",
        "    dense1 = tf.keras.layers.Dense(64, activation='relu')(concatenated)\n",
        "    dense2 = tf.keras.layers.Dense(32, activation='relu')(dense1)\n",
        "    output = tf.keras.layers.Dense(1, activation='linear')(dense2)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='mean_squared_error'\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pERW6yPSOWSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "JvR4WQopObSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for training\n",
        "X_users = ratings_df['user_id_encoded'].values\n",
        "X_movies = ratings_df['movie_id_encoded'].values\n",
        "y = ratings_df['rating'].values\n",
        "\n",
        "# Split data\n",
        "X_users_train, X_users_test, X_movies_train, X_movies_test, y_train, y_test = train_test_split(\n",
        "    X_users, X_movies, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Get number of unique users and movies\n",
        "num_users = len(np.unique(X_users))\n",
        "num_movies = len(np.unique(X_movies))"
      ],
      "metadata": {
        "id": "KNGQTYSzOhqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Collaborative Filtering Model"
      ],
      "metadata": {
        "id": "NfVwhJU0Osdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_model = create_hybrid_model(num_users, num_movies)\n",
        "history = cf_model.fit(\n",
        "    [X_users_train, X_movies_train],\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsRXTj3kOoub",
        "outputId": "08dcece3-ea4b-473d-8518-6778b6adb3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.8831 - val_loss: 0.7982\n",
            "Epoch 2/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.6878 - val_loss: 0.7798\n",
            "Epoch 3/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.6168 - val_loss: 0.7815\n",
            "Epoch 4/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.5410 - val_loss: 0.8101\n",
            "Epoch 5/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.4703 - val_loss: 0.8280\n",
            "Epoch 6/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.4029 - val_loss: 0.8513\n",
            "Epoch 7/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.3465 - val_loss: 0.8914\n",
            "Epoch 8/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2979 - val_loss: 0.9082\n",
            "Epoch 9/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2667 - val_loss: 0.9299\n",
            "Epoch 10/10\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2315 - val_loss: 0.9530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Recommendation system"
      ],
      "metadata": {
        "id": "Dus_euTUO1Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Recommendation Function\n",
        "def get_hybrid_recommendations(input_movies, top_n=5):\n",
        "    \"\"\"\n",
        "    Generate hybrid recommendations combining content and collaborative filtering\n",
        "\n",
        "    Args:\n",
        "    input_movies (list): Input movie names\n",
        "    top_n (int): Number of recommendations to return\n",
        "\n",
        "    Returns:\n",
        "    list: Top recommended movies\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Find movie indices for input movies\n",
        "        input_movie_indices = []\n",
        "        for movie in input_movies:\n",
        "            idx = movies_df[movies_df['title'] == movie].index\n",
        "            if len(idx) > 0:\n",
        "                input_movie_indices.append(idx[0])\n",
        "            else:\n",
        "                print(f\"Warning: {movie} not found in the dataset.\")\n",
        "                return []\n",
        "\n",
        "        # Content-based recommendations\n",
        "        content_scores = np.mean([content_sim_matrix[idx] for idx in input_movie_indices], axis=0)\n",
        "\n",
        "        # Collaborative filtering predictions\n",
        "        sample_user_id = X_users[0]  # Using first user as example\n",
        "        all_movie_ids = np.arange(num_movies)\n",
        "        user_inputs = np.full(len(all_movie_ids), sample_user_id)\n",
        "\n",
        "        # Ensure the same movie indices for both methods\n",
        "        # Align indices between content and collaborative filtering scores\n",
        "        content_scores = content_scores[:len(all_movie_ids)]\n",
        "\n",
        "        # Predict ratings using collaborative filtering\n",
        "        cf_ratings = cf_model.predict([user_inputs, all_movie_ids]).flatten()\n",
        "\n",
        "        # Combine content and collaborative filtering scores\n",
        "        hybrid_scores = 0.5 * content_scores + 0.5 * cf_ratings\n",
        "\n",
        "        # Sort and get top recommendations\n",
        "        top_indices = np.argsort(hybrid_scores)[::-1]\n",
        "\n",
        "        # Filter out input movies\n",
        "        recommendations = []\n",
        "        for idx in top_indices:\n",
        "            rec_movie_title = movies_df.loc[idx, 'title']\n",
        "\n",
        "            if rec_movie_title not in input_movies and len(recommendations) < top_n:\n",
        "                recommendations.append(rec_movie_title)\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "jT9QdGTtO17f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "6mFiP707O7bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recommendations(test_movies, top_n=5):\n",
        "    \"\"\"\n",
        "    Evaluate recommendation quality\n",
        "\n",
        "    Args:\n",
        "    test_movies (list): Movies to test\n",
        "    top_n (int): Number of recommendations\n",
        "\n",
        "    Returns:\n",
        "    dict: Evaluation metrics\n",
        "    \"\"\"\n",
        "    recommendations = get_hybrid_recommendations(test_movies, top_n)\n",
        "\n",
        "    # Genre match calculation\n",
        "    input_genres = set()\n",
        "    for movie in test_movies:\n",
        "        genre = movies_df[movies_df['title'] == movie]['genres'].values[0]\n",
        "        input_genres.update(genre.split('|'))\n",
        "\n",
        "    # Check genre match for recommendations\n",
        "    genre_matches = sum(\n",
        "        any(genre in input_genres for genre in\n",
        "            movies_df[movies_df['title'] == rec]['genres'].values[0].split('|'))\n",
        "        for rec in recommendations\n",
        "    )\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'recommendations': recommendations,\n",
        "        'genre_match_rate': (genre_matches / len(recommendations)) * 100 if recommendations else 0,\n",
        "        'total_recommendations': len(recommendations)\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "PRYB2AC5O-dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage and Evaluation"
      ],
      "metadata": {
        "id": "sLplQt1GPBWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRecommendations for 'Inception (2010)':\")\n",
        "inception_recommendations = get_hybrid_recommendations(['Inception (2010)'])\n",
        "print(inception_recommendations)\n",
        "\n",
        "print(\"\\nEvaluation for 'Inception (2010)':\")\n",
        "evaluation_results = evaluate_recommendations(['Inception (2010)'])\n",
        "print(f\"Genre Match Rate: {evaluation_results['genre_match_rate']:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHLLx6N6PEav",
        "outputId": "40960b4e-783b-4ae5-ee3e-c5d48fd524d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations for 'Inception (2010)':\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "['Sandpiper, The (1965)', 'Secret of Roan Inish, The (1994)', 'GLOW: The Story of the Gorgeous Ladies of Wrestling (2012)', 'Hoop Dreams (1994)', 'Thirteen Days (2000)']\n",
            "\n",
            "Evaluation for 'Inception (2010)':\n",
            "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Genre Match Rate: 60.00%\n"
          ]
        }
      ]
    }
  ]
}